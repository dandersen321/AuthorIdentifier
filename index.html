<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Author Identifier by dandersen321</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/dandersen321/AuthorIdentifier">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/dandersen321/AuthorIdentifier/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/dandersen321/AuthorIdentifier/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Author Identifier</h1>
          <p>Apply Artificial Intelligence to Stylometry to determine authorship of documents whose author is unknown or in question.</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/dandersen321">dandersen321</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h2>
<a id="executive-summary" class="anchor" href="#executive-summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Executive Summary</h2>

<p>It can be hard to determine the author of a document it from the text alone.  This problem may arise when checking for plagiarism or old documents whose authorship is in question.  To solve such a problem, this tool uses a decision tree to learn the style of many authors.  Then using this information it can analyze a document and determine with relatively high accuracy the original author of the work in question.</p>

<h2>
<a id="description" class="anchor" href="#description" aria-hidden="true"><span class="octicon octicon-link"></span></a>Description</h2>

<p>It is often difficult for a human to be able to analyze a document and determine the author.  This linguistic practice is known as Stylometry and has many useful applications.  There are many ways this problem has been approached, but each typically consists of looking for similar patterns between an author and the document being analyzed.  This tool attempts to improve the accuracy of such a method by using a decision tree that can find complex patterns that might be hard for a human to discover.</p>

<p>This implementation was used with a dataset of 24,428 books from the Gutenberg project (<a href="https://www.gutenberg.org/">https://www.gutenberg.org/</a>) but future releases may incorporate other media such as journals and emails.  The tool will analyze each book to try and discover an author's style.  If successful, it can then use this information to predict the author of future books it has not seen before.  This tool has been written in python using the NLTK and sklearn packages for language analysis and AI learning respectively.</p>

<h2>
<a id="why" class="anchor" href="#why" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why</h2>

<p>There are several uses that one can find for the author identifier: </p>

<ol>
<li>Plagiarism: the tool could determine the probability that a paper under one author is actually written from another source</li>
<li>Validity of works:  the tool could determine the legitimacy of works whose authorship is in question.</li>
<li>Discovering authors hidden under pen names: this tool could be used to help determine the author of books that have been written under a pen name</li>
<li>Similar writing styles: the tool could help determine how close different authorâ€™s writing styles are</li>
</ol>

<h2>
<a id="the-process" class="anchor" href="#the-process" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Process</h2>

<h3>
<a id="the-analysis-phase" class="anchor" href="#the-analysis-phase" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Analysis Phase</h3>

<p>From my initial research, I used 31 features in my analysis phase.  They are:</p>

<ul>
<li>apostrophesPerWord: how many apostrophes are used in each word</li>
<li>averageParagraphLength: the average number of sentences in each paragraph</li>
<li>averageWordLength: the average character length of each word</li>
<li>averageWordsPerSentence: the average words in each sentence</li>
<li>bigraphs: how often the two character sequence appears in a word

<ul>
<li>bigraph-co</li>
<li>bigraph-lc</li>
<li>bigraph-me</li>
<li>bigraph-we</li>
</ul>
</li>
<li>digitFraction: how many characters are digits</li>
<li>numberOfWords: how many words the document contains</li>
<li>uppercaseFraction: how many words start with an uppercase character</li>
<li>whitespaceFraction: the ratio of the whitespace to words </li>
<li>WPT: (Words Per Thousand) how often a word occurs out of every thousand words

<ul>
<li>WPT-and</li>
<li>WPT-because</li>
<li>WPT-but</li>
<li>WPT-colon</li>
<li>WPT-comma</li>
<li>WPT-doubleHyphen</li>
<li>WPT-exclamationMark</li>
<li>WPT-however</li>
<li>WPT-hyphen</li>
<li>WPT-if</li>
<li>WPT-might</li>
<li>WPT-more</li>
<li>WPT-must</li>
<li>WPT-quote</li>
<li>WPT-semicolon</li>
<li>WPT-since</li>
<li>WPT-that</li>
<li>WPT-this</li>
<li>WPT-very</li>
</ul>
</li>
</ul>

<p>I calculated these features on each document then saved the results in a json file.  In this way we don't have to analyze each document every time the program is run (a full analysis on all 24,428 books takes about 8 hours).</p>

<h3>
<a id="creating-the-decision-tree" class="anchor" href="#creating-the-decision-tree" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating the decision tree</h3>

<p>To analyze the data I used a decision tree using python library sklearn's implementation.  The decision tree works to try and compartmentalize the data into leaf nodes where each leaf contains only (or a large majority) of one author.  A simple example would be given we had 3 authors: star, circle, and triangle and we were using 2 parameters: averageParagraphLength and WPT-and.  We might end up with the following graph:</p>

<p><img src="https://raw.githubusercontent.com/dandersen321/AuthorIdentifier/master/decisionTreeBasicGraph.PNG" alt=""></p>

<p>where each shape represents one book by that author.  We would then create the following decision tree:</p>

<p><img src="https://raw.githubusercontent.com/dandersen321/AuthorIdentifier/master/decisionTreeBasicTree.PNG" alt=""></p>

<p>In this way, if were given the features of any random book we would be able to identify the author.  The decision tree used for this project is quite more complicated and the data not as perfectly categorized.  If you want to see the complexity of the tree you can get a look here: <a href="https://raw.githubusercontent.com/dandersen321/AuthorIdentifier/master/decisionTree.pdf">decision tree pdf</a>.</p>

<h2>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h2>

<p>Using this method I was able to predict the correct author with a relatively high degree of accuracy.  This accuracy was correlated with two factors: the number of authors used and the minimum number of books each author must have written to be included in the dataset.  The following graphs show the results.</p>

<p><img src="https://raw.githubusercontent.com/dandersen321/AuthorIdentifier/master/authorsUsedOnAccuracy.PNG" alt=""></p>

<p>We can see that as the number of authors increase, the accuracy decreases until it steadies at around 45% accuracy.  So given a high school classroom size of about 30 students we would expect a 75% accuracy in the prediction of anonymous documents and given a large college course of 250 students we would expect 45% accuracy.  </p>

<p>A second but less impactful variable was the number of books an author needed to write to be included in the dataset.  As we can see from the following graph, the more books we have to analyze from an author results in a small positive correlation to our accuracy.</p>

<p><img src="https://raw.githubusercontent.com/dandersen321/AuthorIdentifier/master/minBooks.png" alt=""> </p>

<h2>
<a id="features-of-importance" class="anchor" href="#features-of-importance" aria-hidden="true"><span class="octicon octicon-link"></span></a>Features of Importance</h2>

<p>After looking at the results, I also explored which features improved the accuracy the most.  The first way was to use only that feature and see how well I could predict the accuracy.  This resulted in expectedly low accuracy, but shows which features are strong on their own.</p>

<p><img src="https://raw.githubusercontent.com/dandersen321/AuthorIdentifier/master/SingleParam.png" alt=""></p>

<p>I then looked at how the features combined to affect accuracy.  I did this by starting with zero features, and then adding one random feature and computing it's accuracy in predicting authors.  This resulted in the following data.</p>

<p><img src="https://raw.githubusercontent.com/dandersen321/AuthorIdentifier/master/addingFeatures.PNG" alt=""></p>

<p>As we can see, the first features are the most significant but after several features have been added each additional one has a smaller impact.  We also see that certain features that did not well on the single parameter test also added little or even hurt the accuracy.</p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
